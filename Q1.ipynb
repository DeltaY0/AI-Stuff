{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccdd6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e8d5ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  src_bclasstes  dst_bclasstes  count  srv_count  serror_rate  \\\n",
      "0         0            520              0    428        428          0.0   \n",
      "1         0              0              0    131         18          0.0   \n",
      "2         0              0              0     20          8          1.0   \n",
      "3         0           1235            404      1          4          0.0   \n",
      "4         0            224           1415      1          1          0.0   \n",
      "\n",
      "   srv_serror_rate  rerror_rate  srv_rerror_rate  same_srv_rate  ...  \\\n",
      "0              0.0          0.0              0.0           1.00  ...   \n",
      "1              0.0          1.0              1.0           0.14  ...   \n",
      "2              1.0          0.0              0.0           0.40  ...   \n",
      "3              0.0          0.0              0.0           1.00  ...   \n",
      "4              0.0          0.0              0.0           1.00  ...   \n",
      "\n",
      "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0                 255                    1.00                    0.00   \n",
      "1                  18                    0.07                    0.06   \n",
      "2                  68                    0.27                    0.02   \n",
      "3                 179                    0.72                    0.12   \n",
      "4                  48                    1.00                    0.00   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                         1.00                         0.00   \n",
      "1                         0.00                         0.00   \n",
      "2                         0.01                         0.00   \n",
      "3                         0.04                         0.02   \n",
      "4                         0.02                         0.00   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0                   0.0                      0.00                  0.00   \n",
      "1                   0.0                      0.00                  1.00   \n",
      "2                   1.0                      1.00                  0.00   \n",
      "3                   0.0                      0.01                  0.04   \n",
      "4                   0.0                      0.00                  0.00   \n",
      "\n",
      "   dst_host_srv_rerror_rate        class  \n",
      "0                       0.0  anomalclass  \n",
      "1                       1.0  anomalclass  \n",
      "2                       0.0  anomalclass  \n",
      "3                       0.0       normal  \n",
      "4                       0.0       normal  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('Q1_data.csv')\n",
    "feature_matrix = raw_data.drop('class', axis=1).values\n",
    "label_vector = np.where(raw_data['class'] == 'normal', 0, 1)\n",
    "\n",
    "print(raw_data.head());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bfc7216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 23 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     200 non-null    int64  \n",
      " 1   src_bclasstes                200 non-null    int64  \n",
      " 2   dst_bclasstes                200 non-null    int64  \n",
      " 3   count                        200 non-null    int64  \n",
      " 4   srv_count                    200 non-null    int64  \n",
      " 5   serror_rate                  200 non-null    float64\n",
      " 6   srv_serror_rate              200 non-null    float64\n",
      " 7   rerror_rate                  200 non-null    float64\n",
      " 8   srv_rerror_rate              200 non-null    float64\n",
      " 9   same_srv_rate                200 non-null    float64\n",
      " 10  diff_srv_rate                200 non-null    float64\n",
      " 11  srv_diff_host_rate           200 non-null    float64\n",
      " 12  dst_host_count               200 non-null    int64  \n",
      " 13  dst_host_srv_count           200 non-null    int64  \n",
      " 14  dst_host_same_srv_rate       200 non-null    float64\n",
      " 15  dst_host_diff_srv_rate       200 non-null    float64\n",
      " 16  dst_host_same_src_port_rate  200 non-null    float64\n",
      " 17  dst_host_srv_diff_host_rate  200 non-null    float64\n",
      " 18  dst_host_serror_rate         200 non-null    float64\n",
      " 19  dst_host_srv_serror_rate     200 non-null    float64\n",
      " 20  dst_host_rerror_rate         200 non-null    float64\n",
      " 21  dst_host_srv_rerror_rate     200 non-null    float64\n",
      " 22  class                        200 non-null    object \n",
      "dtypes: float64(15), int64(7), object(1)\n",
      "memory usage: 36.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.info());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b6a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1180733  -0.07777228 -0.2117447  ... -0.67984097 -0.4467788\n",
      "  -0.43567987]\n",
      " [-0.1180733  -0.07810672 -0.2117447  ... -0.67984097  2.41169081\n",
      "   2.35177931]\n",
      " [-0.1180733  -0.07810672 -0.2117447  ...  1.47462258 -0.4467788\n",
      "  -0.43567987]\n",
      " ...\n",
      " [-0.1180733  -0.07810672 -0.2117447  ...  1.47462258 -0.4467788\n",
      "  -0.43567987]\n",
      " [-0.1180733  -0.07800703 -0.15243546 ... -0.65829634 -0.4181941\n",
      "  -0.40780528]\n",
      " [-0.1180733  -0.07808743 -0.19969542 ... -0.67984097 -0.4467788\n",
      "  -0.43567987]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler() # to normalize all the data\n",
    "feature_matrix = scaler.fit_transform(feature_matrix)\n",
    "print(feature_matrix); # feature_matrix has the training data without class field from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2737afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: Normal Count = 70\n",
      "Training Set: Anomaly Count = 70\n",
      "Testing Set:  Normal Count = 30\n",
      "Testing Set:  Anomaly Count = 30\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "training_features, testing_features, training_labels, testing_labels = train_test_split(\n",
    "    feature_matrix,\n",
    "    label_vector,\n",
    "    test_size=0.3,\n",
    "    stratify=label_vector,\n",
    "    random_state=665\n",
    "    );\n",
    "\n",
    "print(f\"Training Set: Normal Count = {np.sum(training_labels == 0)}\")\n",
    "print(f\"Training Set: Anomaly Count = {np.sum(training_labels == 1)}\")\n",
    "print(f\"Testing Set:  Normal Count = {np.sum(testing_labels == 0)}\")\n",
    "print(f\"Testing Set:  Anomaly Count = {np.sum(testing_labels == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5137893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(val):\n",
    "    # step function\n",
    "    if val >= 0: return 1;\n",
    "    return 0;\n",
    "\n",
    "def train_perceptron(features, labels, learning_rate=0.1, max_iterations=1000):\n",
    "    num_samples, num_features = features.shape\n",
    "\n",
    "    # init weights and threshold\n",
    "    weights = np.zeros(num_features)\n",
    "    bias = 0.0\n",
    "\n",
    "    for it in range(max_iterations):\n",
    "        for idx in range(num_samples):\n",
    "            curr_sample = features[idx];\n",
    "            true_label = labels[idx];\n",
    "\n",
    "            # fn = x0 * w0 + x1 * w1 + .... + bias\n",
    "            fn = np.dot(curr_sample, weights) + bias;\n",
    "            predicted_val = activation(fn);\n",
    "\n",
    "            # update weigths\n",
    "            if true_label != predicted_val:\n",
    "                err = true_label - predicted_val;\n",
    "\n",
    "                weights = weights + (learning_rate * err * curr_sample);\n",
    "                bias = bias + (learning_rate * err);\n",
    "    \n",
    "    return weights, bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ead6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, weights, bias):\n",
    "    pred_list = [];\n",
    "    num_samples = len(features);\n",
    "\n",
    "    for idx in range(num_samples):\n",
    "        curr_sample = features[idx];\n",
    "\n",
    "        fn = np.dot(curr_sample, weights) + bias;\n",
    "        pred_val = activation(fn);\n",
    "\n",
    "        pred_list.append(pred_val);\n",
    "\n",
    "    return np.array(pred_list);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed668c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "trained_weights, trained_bias = train_perceptron(training_features, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "575a4032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Classification Accuracy: 93.33%\n"
     ]
    }
   ],
   "source": [
    "predicted_test_labels = predict(testing_features, trained_weights, trained_bias)\n",
    "perceptron_accuracy = accuracy_score(testing_labels, predicted_test_labels)\n",
    "\n",
    "print(f\"Perceptron Classification Accuracy: {perceptron_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd46e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "analysis for K = 2:\n",
      "  cluster id 0: normal=0.0%, anomaly=100.0%\n",
      "  cluster id 1: normal=71.4%, anomaly=28.6%\n",
      "  classification accuracy (on train set): 80.00%\n",
      "\n",
      "analysis for K = 3:\n",
      "  cluster id 0: normal=25.0%, anomaly=75.0%\n",
      "  cluster id 1: normal=0.0%, anomaly=100.0%\n",
      "  cluster id 2: normal=86.5%, anomaly=13.5%\n",
      "  classification accuracy (on train set): 88.57%\n",
      "\n",
      "analysis for K = 4:\n",
      "  cluster id 0: normal=25.0%, anomaly=75.0%\n",
      "  cluster id 1: normal=0.0%, anomaly=100.0%\n",
      "  cluster id 2: normal=86.3%, anomaly=13.7%\n",
      "  cluster id 3: normal=100.0%, anomaly=0.0%\n",
      "  classification accuracy (on train set): 88.57%\n",
      "\n",
      "optimal number of clusters (K): 3\n"
     ]
    }
   ],
   "source": [
    "best_k_value = 0\n",
    "highest_training_accuracy = 0.0\n",
    "\n",
    "# try different num of clusters\n",
    "for num_clusters in [2, 3, 4]:\n",
    "    \n",
    "    # Initialize and fit K-Means\n",
    "    kmeans_algorithm = KMeans(n_clusters=num_clusters, random_state=665, n_init=10)\n",
    "    kmeans_algorithm.fit(training_features)\n",
    "    \n",
    "    cluster_assignments = kmeans_algorithm.labels_\n",
    "    \n",
    "    print(f\"\\nanalysis for K = {num_clusters}:\")\n",
    "    \n",
    "    # This map will store which class (0 or 1) each cluster represents\n",
    "    id_class_map = {}\n",
    "    \n",
    "    for cluster_id in range(num_clusters):\n",
    "        # get all points that belong to this cluster\n",
    "        indices_in_cluster = np.where(cluster_assignments == cluster_id)\n",
    "        true_labels_in_cluster = training_labels[indices_in_cluster]\n",
    "        \n",
    "        # calculate the num of elements in cluster\n",
    "        normal_count = np.sum(true_labels_in_cluster == 0)\n",
    "        anomaly_count = np.sum(true_labels_in_cluster == 1)\n",
    "        total_count_in_cluster = normal_count + anomaly_count\n",
    "        \n",
    "        # make sure the cluster isn't empty\n",
    "        if total_count_in_cluster == 0:\n",
    "            continue;\n",
    "            \n",
    "        percent_normal = (normal_count / total_count_in_cluster) * 100;\n",
    "        percent_anomaly = (anomaly_count / total_count_in_cluster) * 100;\n",
    "        \n",
    "        print(f\"  cluster id {cluster_id}: normal={percent_normal:.1f}%, anomaly={percent_anomaly:.1f}%\")\n",
    "        \n",
    "        # give the clutter the label of the majority\n",
    "        if normal_count > anomaly_count:\n",
    "            id_class_map[cluster_id] = 0 # normal\n",
    "        else:\n",
    "            id_class_map[cluster_id] = 1 # anomaly\n",
    "            \n",
    "    # calc accuracy\n",
    "    predicted_labels_from_clustering = []\n",
    "    for assigned_cluster in cluster_assignments:\n",
    "        predicted_label = id_class_map[assigned_cluster]\n",
    "        predicted_labels_from_clustering.append(predicted_label)\n",
    "        \n",
    "    current_accuracy = accuracy_score(training_labels, predicted_labels_from_clustering)\n",
    "    print(f\"  classification accuracy (on train set): {current_accuracy * 100:.2f}%\");\n",
    "    \n",
    "    # Keep track of the best K\n",
    "    if current_accuracy > highest_training_accuracy:\n",
    "        highest_training_accuracy = current_accuracy;\n",
    "        best_k_value = num_clusters;\n",
    "\n",
    "print(f\"\\noptimal number of clusters (K): {best_k_value}\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
